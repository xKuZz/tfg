% !TEX options=--shell-escape
%\documentclass[a4paper,11pt]{book}
\documentclass[a4paper,oneside,11pt,titlepage]{book}
%\usepackage{listings}
\usepackage[utf8]{inputenc}
\usepackage[spanish]{babel}

% \usepackage[style=list, number=none]{glossary} %
\usepackage{titlesec}
\setcounter{secnumdepth}{3}

%\usepackage{pailatino}
\usepackage{float}
\decimalpoint
\usepackage{dcolumn}
\newcolumntype{.}{D{.}{\esperiod}{-1}}
\makeatletter
\addto\shorthandsspanish{\let\esperiod\es@period@code}
\makeatother

\usepackage{booktabs}
%\usepackage[chapter]{algorithm}
\RequirePackage{verbatim}
\usepackage[newfloat]{minted}
\usepackage{caption}
\usepackage{multirow}
%\RequirePackage[Glenn]{fncychap}
\usepackage{fancyhdr}
\usepackage{graphicx}
\usepackage{afterpage}
\usepackage{parskip}
\usepackage{longtable}
\usepackage{algpseudocode}
\usepackage{algorithm}
\makeatletter
\renewcommand{\ALG@name}{Pseudocódigo}
\makeatother

\usepackage[normalem]{ulem}
\useunder{\uline}{\ul}{}

\usepackage[pdfborder={000}]{hyperref} %referencia

% ********************************************************************
% Re-usable information
% ********************************************************************
\newcommand{\myTitle}{Desarrollo e Implementación de modelos paralelos de Soft Computing en CUDA\xspace}
\newcommand{\myDegree}{Grado en Ingeniería Informática\xspace}
\newcommand{\myName}{David Criado Ramón\xspace}
\newcommand{\myProf}{Manuel I. Capel Tuñón\xspace}
\newcommand{\myOtherProf}{María del Carmen Pegalajar Jiménez\xspace}
%\newcommand{\mySupervisor}{Put name here\xspace}
\newcommand{\myFaculty}{Escuela Técnica Superior de Ingenierías Informática y de
Telecomunicación\xspace}
\newcommand{\myFacultyShort}{E.T.S. de Ingenierías Informática y de
Telecomunicación\xspace}
\newcommand{\myDepartment}{Departamento de Ciencias de la Computación e Inteligencia Artificial\xspace}
\newcommand{\myUni}{\protect{Universidad de Granada}\xspace}
\newcommand{\myLocation}{Granada\xspace}
\newcommand{\myTime}{\today\xspace}
\newcommand{\myVersion}{Version 0.1\xspace}



\hypersetup{
pdfauthor = {\myName (email (en) ugr (punto) es)},
pdftitle = {\myTitle},
pdfsubject = {},
pdfkeywords = {palabra_clave1, palabra_clave2, palabra_clave3, ...},
pdfcreator = {LaTeX con el paquete ....},
pdfproducer = {pdflatex}
}

%\hyphenation{}


%\usepackage{doxygen/doxygen}
%\usepackage{pdfpages}
\usepackage{url}
\usepackage{colortbl,longtable}
\usepackage{minted}
\setminted[python]{frame=lines,framesep=2mm, fontsize=\footnotesize}
\usepackage[stable]{footmisc}
\usepackage[table,xcdraw]{xcolor}
\usepackage{longtable}
%\usepackage{index}

%\makeindex
%\usepackage[style=long, cols=2,border=plain,toc=true,number=none]{glossary}
% \makeglossary

% Definición de comandos que me son tiles:
%\renewcommand{\indexname}{Índice alfabético}
%\renewcommand{\glossaryname}{Glosario}

\pagestyle{fancy}
\fancyhf{}
\fancyhead[LO]{\leftmark}
\fancyhead[RE]{\rightmark}
\fancyhead[RO,LE]{\textbf{\thepage}}
\renewcommand{\chaptermark}[1]{\markboth{\textbf{#1}}{}}
\renewcommand{\sectionmark}[1]{\markright{\textbf{\thesection. #1}}}
\setlength{\headheight}{1.5\headheight}

\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}
%Definimos los tipos teorema, ejemplo y definición podremos usar estos tipos
%simplemente poniendo \begin{teorema} \end{teorema} ...
\newtheorem{teorema}{Teorema}[chapter]
\newtheorem{ejemplo}{Ejemplo}[chapter]
\newtheorem{definicion}{Definición}[chapter]
\newenvironment{code}{\captionsetup{type=listing}}{}
\SetupFloatingEnvironment{listing}{name=Código Fuente}
\definecolor{gray97}{gray}{.97}
\definecolor{gray75}{gray}{.75}
\definecolor{gray45}{gray}{.45}
\definecolor{gray30}{gray}{.94}

\usepackage{appendix}

\newcommand{\cuda}{\textit{CUDA} }
\newcommand{\cudanospace}{\textit{CUDA}}
\newcommand{\bigrule}{\titlerule[0.5mm]}


%Para conseguir que en las páginas en blanco no ponga cabecerass
\makeatletter
\def\clearpage{%
  \ifvmode
    \ifnum \@dbltopnum =\m@ne
      \ifdim \pagetotal <\topskip
        \hbox{}
      \fi
    \fi
  \fi
  \newpage
  \thispagestyle{empty}
  \write\m@ne{}
  \vbox{}
  \penalty -\@Mi
}
\makeatother

\usepackage{pdfpages}
\usepackage{enumerate}
\begin{document}
\input{portada/portada}
\input{prefacios/prefacio}  
\frontmatter
\tableofcontents
\listoffigures
\listoftables

%
\mainmatter
\setlength{\parskip}{5pt}
\chapter{Introducción y motivación.}
\section{Introducción y motivación.}

La tecnología propietaria \textit{CUDA (Computer Unified Device Architecture)} \cite{cuda} de NVIDIA, presentada en junio de 2007 y aplicable tanto a la arquitectura de las tarjetas gráficas de la misma marca como al modelo de programación genérico asociado, a lo largo de la última década, ha supuesto un gran cambio en las implementaciones paralelas de algoritmos y, además, su uso es muy popular en la comunidad científica.\\

La estructura de la GPU \textit{(Graphics Processing Unit)}, utilizando un mayor número de núcleos a cambio de una velocidad de reloj más baja a la que podemos encontrar en una CPU \textit{(Central Processing Unit)}, es de especial utilidad en operaciones masivamente paralelas, pudiendo llegar a proporcionar tiempos de ejecución considerablemente mejores a los que podríamos obtener usando una CPU.\\

Por otro lado, los algoritmos y técnicas de \textit{Soft Computing} se corresponden con una rama de la Inteligencia Artificial en la que no podemos calcular soluciones exactas en tiempo polinómico y/o en los que la información es incompleta, incierta o inexacta.\\

El propósito de este trabajo de fin de grado es la implementación en \textit{CUDA} de algunos de estos modelos de \textit{Soft Computing}, combinando \textit{CUDA} con el \textit{framework} de computación en clúster \textit{Spark} \cite{spark}. De esta manera, los algoritmos que se desarrollen podrán ser ejecutados tanto en un único dispositivo como en un clúster con múltiples dispositivos \textit{CUDA}. Para ello, se analizarán los algoritmos y sus posibilidades de paralelización, se realizarán las implementaciones adecuadas y se evaluará el rendimiento de las mismas utilizando conjunto de datos con un número de muestras elevado.\\

Tras evaluar varias opciones, se optó por desarrollar dos modelos distintos: los mapa auto-organizados de Kohonen \cite{kohonensom} y los árboles de decisión \cite{arbol}.\\

\section{Descripción del proyecto.}
En este proyecto se pretende que el alumno diseñe, desarrolle e implemente modelos en paralelo asociados a algoritmos tradicionales de \textit{Soft Somputing}. Para ello se utilizará el lenguaje \textit{CUDA}, pudiendo de esta manera aprovechar las características de los dispositivos GPUs. Para probar estos modelos se escogerán problemas relacionados con Big Data y que tengan una gran carga computacional.

\section{Requisitos de hardware y software para el proyecto.}
\underline{Requisitos de \textit{hardware}}\\
El único requisito de \textit{hardware} en este proyecto es disponer de un sistema con un dispositivo \textit{CUDA}. \\

\underline{Dependencias de \textit{software}}\\
Para las implementaciones del proyecto se han usado:
\begin{itemize}
  \item Los \textit{drivers} apropiados para el dispositivo \textit{CUDA} del sistema.
  \item \textit{Python 3.6} con los paquetes \textit{NumPy} y \textit{Numba}.
  \item \textit{Spark} 2.4.0 con \textit{Hadoop} 2.7.3
\end{itemize}

\newpage
\section{Planificación de tareas.}
Este proyecto fue desarrollado mayoritariamente durante el segundo cuatrimestre del curso, precedido por el estudio de las tecnologías utilizadas (\textit{CUDA} y \textit{Spark}).\\

\begin{table}[ht]
\centering
\begin{tabular}{|c|c|}
\hline
\textit{\textbf{Tarea}}                                                                                                                     & \textit{\textbf{Fecha finalización}} \\ \hline
\textbf{Estudio sobre CUDA.}                                                                                                                & 15 Marzo 2019                        \\ \hline
\textbf{\begin{tabular}[c]{@{}c@{}}Estudio de bibliografía\\ y selección de modelo a implementar:\\ Árbol CART.\end{tabular}}               & 28 Marzo 2019                        \\ \hline
\textbf{\begin{tabular}[c]{@{}c@{}}Estudio de bibliografía\\ del modelo:\\ Mapa auto-organizado on-line.\end{tabular}}                      & 7 Abril 2019                         \\ \hline
\textbf{\begin{tabular}[c]{@{}c@{}}Estudio de bibliografía\\ y selcción de modelo a implementar:\\ Mapa auto-organizado batch\end{tabular}} & 12 Abril 2019                        \\ \hline
\textbf{\begin{tabular}[c]{@{}c@{}}Implementación en CUDA de mapa \\ auto-organizado batch.\end{tabular}}                                   & 17 Abril 2019                        \\ \hline
\textbf{\begin{tabular}[c]{@{}c@{}}Implementación en CUDA\\ de árbol de decisión CART\\ (sólo clasificación binaria).\end{tabular}}         & 23 Abril 2019                        \\ \hline
\textbf{Estudio de Spark.}                                                                                                                  & 6 Mayo 2019                          \\ \hline
\textbf{\begin{tabular}[c]{@{}c@{}}Incorporación de Spark al mapa \\ auto-organizado batch\end{tabular}}                                    & 9 Mayo 2019                          \\ \hline
\textbf{\begin{tabular}[c]{@{}c@{}}Incorporación de Spark al \\ árbol de decisión.\end{tabular}}                                            & 14 Mayo 2019                         \\ \hline
\textbf{\begin{tabular}[c]{@{}c@{}}Primera fase de redacción \\ de memoria.\end{tabular}}                                                   & 25 Mayo 2019                         \\ \hline
\textbf{\begin{tabular}[c]{@{}c@{}}Revisión y corrección de erratas \\ en mapa auto-organizado.\end{tabular}}                               & 5 Junio 2019                         \\ \hline
\textbf{\begin{tabular}[c]{@{}c@{}}Revisión y optimización del\\  árbol de decisión.\end{tabular}}                                          & 29 Junio 2019                        \\ \hline
\textbf{Finalización de la memoria.}                                                                                                        & 30 Julio 2019                        \\ \hline
\end{tabular}
\caption{Tareas realizadas durante el desarrollo del proyecto.}
\label{tab:tareas}
\end{table}

\newpage
\section{Objetivos.}
\begin{itemize}
    \item Iniciarse, estudiar y profundizar en el desarrollo de algoritmos paralelos en \textit{CUDA}.
    \item Analizar algoritmos de \textit{Soft Computing}, evaluando las capacidades que tienen para ser paralelizados.
    \item Implementar los algoritmos seleccionados en \textit{CUDA}.
    \item Combinar el uso de \textit{CUDA} y \textit{Spark} para resolver la paralelización masiva de problemas de forma eficiente.
    \item Utilizar conjuntos de datos de \textit{Big Data} que sean computacionalmente exigentes para el desarrollo de las pruebas.
    \item Realizar una evaluación de la calidad de los resultados obtenidos.
\end{itemize}

\section{Estructura del documento.}

\begin{itemize}
    \item En el primer capítulo, \textbf{Introducción y motivación}, hemos comentado los propósitos para la realización de este trabajo y el grado de consecución de los objetivos planteados.
    \item En el segundo capítulo, \textbf{Modelos de Soft Computing considerados}, explicamos los fundamentos teóricos de los algoritmos de \textit{Soft Computing} que hemos decidido paralelizar.
    \item En el tercer capítulo, \textbf{Estado del arte: trabajos relacionados}, realizamos un breve repaso de algunas implementaciones de los modelos propuestos que hace uso de CUDA presentes en la literatura.
    \item En el cuarto capítulo, \textbf{Implementación}, comentamos el proceso de desarrollo seguido así como explicamos las soluciones finales implementadas y comentamos algunas de las alternativas y problemas que surgieron durante la realización de las implementaciones.
    \item En el quinto capítulo, \textbf{Desarrollo de pruebas y análisis de resultados}, indicamos qué pruebas se han realizado, mostramos los resultados obtenidos y analizamos en profundidad las implicaciones de los mismos.
    \item En el último capítulo, \textbf{Conclusiones y trabajos futuros}, finalizamos el trabajo destacando las implicaciones más importantes de los resultados obtenidos y mostramos posibles alternativas para ampliar nuestro trabajo.
\end{itemize}

%\input{capitulos/TECNOLOGIAS}
\input{capitulos/MODELOS}
\input{capitulos/CUDA}
\chapter{Estado del arte: trabajos relacionados.}
La paralelización en \textit{CUDA} de los mapas auto-organizados de Kohonen y de los árboles de decisión son problemas que han sido previamente estudiados en la literatura.\\

En \textbf{\textit{Parallel High Dimensional Self Organizing Maps Using CUDA}}, Codevilla, Bothelo, Filho y Gaya \cite{cudasomonline} proponen una implementación en \textit{CUDA} para la formulación tradicional del mapa auto-organizado de Kohonen. En ella, proponen una versión en la que cada iteración se subdivide en 3 fases. Una primera, en la que con un valor \textit{p} arbitrario, menor que el número de hebras por bloque, que indica cuantos ``pasos'' debe realizar una hebra para el cálculo de la distancia euclídea, es decir, un reparto de los cálculos necesarios para obtener la distancia euclídea que depende de un parámetro indicado por el usuario; una reducción, para encontrar la mejor distancia entre las neuronas; y un método para la adaptación de pesos de neuronas cuyo grado de paralelismo depende de dimensión del problema (tamaño de una neurona). \\

En \textbf{\textit{Parallel Batch Self-Organizing Map on Graphics Processing Unit Using CUDA}}, Daneshpajouh, Delisle, Boisson, Krajecki y Zakaria \cite{cudasombatch} plantean una adaptación en CUDA para la versión iterativa de cómputo en \textit{batchs} del mapa auto-organizado de Kohonen. En ella, aprovechan las capacidades de concurrencia disponibles en los dispositivos CUDA, paralelizando parte del algoritmo y dejando otra parte para ser realizada con la CPU.\\

Con respecto a los árboles de decisión, \textbf{\textit{CUDT: a CUDA based decision tree algorithm}}, de Lo, Chang, Sheu, Chiu y Yuan \cite{cudt}, será la base de la implementación que nosotros vamos a realizar y se basa en el uso de la operación de la suma prefija, suma acumulada o \textit{scan} para resolver árboles de decisión cuyo objetivo es la clasificación de problemas con respuesta binaria.\\

Aparte de la aproximación por especialización presentada en el trabajo anterior, existe otra alternativa, más frecuente, versátil y aplicable a diferentes tipos de problemas a resolver, se basa en la discretización de las variables utilizadas durante la construcción del árbol y el uso de histogramas para ello. Esto lo podemos ver en \textbf{\textit{Implementing Streaming Parallel Decision Trees on Graphic Processing Units}}, de Svantesson \cite{svatensson}, donde el objeto principal de su trabajo es paralelizar en \textit{CUDA} los cálculos asociados a los histogramas utilizados en \textbf{\textit{Streaming Parallel Decision Trees}}, de Ben-Haim y Tom-Tov \cite{spdt}, un algoritmo para la paralelización de árboles para CPU.\\
\input{capitulos/IMPLEMENTACION}
\input{capitulos/PRUEBAS}
\input{capitulos/CONCLUSIONES}
%\input{capitulos/ESTADOARTE}
%\input{capitulos/SOM}
%\input{capitulos/ARBOL}
%\input{capitulos/01_Introduccion}
%
%\input{capitulos/02_EspecificacionRequisitos}
%
%\input{capitulos/03_Planificacion}
%
%\input{capitulos/04_Analisis}
%
%\input{capitulos/05_Diseno}
%
%\input{capitulos/06_Implementacion}
%
%\input{capitulos/07_Pruebas}
%
%\input{capitulos/08_Conclusiones}
%
%%\chapter{Conclusiones y Trabajos Futuros}
%
%
%%\nocite{*}
%\bibliographystyle{miunsrturl} 
\bibliographystyle{proyectobibstyle} 
\bibliography{bibliografia/bibliografia}\addcontentsline{toc}{chapter}{Bibliografía}
%

%\input{apendices/manual_usuario/manual_usuario}
%\input{capitulos/ESPTECNICAS}
%\input{glosario/entradas_glosario}
% \addcontentsline{toc}{chapter}{Glosario}
% \printglossary

\thispagestyle{empty}

\end{document}


 