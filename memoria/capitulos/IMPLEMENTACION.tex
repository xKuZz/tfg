\chapter{Implementación.}
\input{capitulos/CUDA}
\section{Proceso de implementación.}
Para realizar la implementación de cada algoritmo hemos realizado un proceso cíclico divido en 3 fases:

\begin{itemize}
	\item \textbf{Análisis} - En la primera iteración, analizar los trabajos relacionados. En las posteriores, analizar los resultados obtenidos del profiler, determinar los cuellos de botella y buscar posibles alternativas para solucionar el problema.
	\item \textbf{Implementación} - Realizar la implementación en CUDA de los cambios o elementos nuevos obtenidos del proceso de análisis.
	\item \textbf{Profiling} - Utilizar el profiler de NVIDIA, \textit{nvprof}, sobre un ejemplo razonable para evaluar el rendimiento del algoritmo.
\end{itemize}

En este capítulo, explicaremos las soluciones finales a las que hemos llegado y destacaremos algunas de las decisiones tomadas y el razonamiento para haberlas seleccionado. Para facilitar la comprensión y tener en cuenta las dependencias de datos de los algoritmos durante el proceso de desarrollo hemos utilizado diagramas de flujo adaptados que nos permitan tener una visión general de las dependencias existentes entre los procesos y datos de una manera esquemática para cada uno de los modelos. 

\section{Desarrollo del mapa autoorganizado de Kohonen.}
Para implementar los mapas autoorganizados de Kohonen, primero consideramos la versión tradicional \textit{online} y, posteriormente, tras ver las limitaciones de la primera, evaluamos la versión computada en \textit{batchs}. Ambas implemntaciones ha sido realizadas tanto para CPU secuencial (un núcleo) como para CUDA. El código desarrollado en la versión para CPU secuencial ha sido realizado en \textit{Python} usando \textit{NumPy} conforme a lo explicado al presentar el modelo. En este capítulo, nos centramos en la implementación realizada en \textit{CUDA}.

\subsection{Limitaciones del mapa autoorganizado online.}
En la figura \ref{img:somonline} podemos observar un esquema de cómo podríamos resolver el mapa autoorganizado online utilizando CUDA.

\begin{figure}[ht]
\centering
\includegraphics[scale=0.35]{imagenes/flujosomonline.png}
\caption{Diagrama de flujo para el mapa autoorganizado online.}
\label{img:somonline}
\end{figure}

Mientras que este fue el punto de partida para la realización de este trabajo tuvimos que descartar esta versión del algoritmo. Mientras que nosotros buscamos resolver problemas con un gran número de muestras utilizando \textit{CUDA} y \textit{Spark}, dicho algoritmo requiere que una única muestra sea evaluada por iteración, ya que cada muestra, al ser evaluada, modifica los pesos para la siguiente iteración en la que otra muestra realizará el mismo proceso. Por ello, esta opción ha sido descartada aunque si nos encontrásemos ante un problema con un número de neuronas superior al número de muestras de entrada, factor que no parece natural en un algoritmo cuyo principal uso es el \textit{clustering}, el algoritmo es susceptible a ser paralelizado en base al número de neuronas del mapa. \\

Determinada esa limitación fundamental, vamos a centrarnos en la versión del mapa autoorganizado que hemos implementado, el mapa autoorganizado \textit{batch}.

\subsection{Desarrollo del mapa autoorganizado batch.}
Para el desarrollo de esta versión del algoritmo de una manera eficiente dos factores han sido clave: el \textbf{uso de la memoria compartida} y \textbf{la reducción}.
Podemos descomponer la implementación del algoritmo en resolver los siguientes subproblemas:

\begin{itemize}
	\item 1. Inicialización aleatoria de la matriz de pesos.
	\item 2. Cálculo de las distancias euclídeas entre todas las muestras y los pesos.
	\item 3. Encontrar la BMU para cada muestra.
	\item 4. Actualizar la matriz de pesos.
	\item 5. Actualizar los parámetros de control.
\end{itemize}

\subsubsection{Inicialización aleatoria de la matriz de pesos.}
Este proceso es realizado por el nodo de Spark que controlaría la ejecución del clúster una única vez al inicio del algoritmo, pero utilizando la GPU. \textit{Numba CUDA} nos proporciona herramientas para la generación de valores flotantes en el rango comprendido entre 0 y 1 basadas en el método de Box-Muller. Hemos utilizado esta herramienta para la generación de nuestra matriz de vectores de pesos inicial.

\begin{code}
\begin{minted}[fontsize=\footnotesize]{python}
@cuda.jit
def cuda_init_weights(rng_states, weights):
    idx = cuda.grid(1)
    if idx < weights.size:
        weights[idx] = xoroshiro128p_uniform_float32(rng_states, idx)

d_weights = cuda.device_array(rows * cols * d, np.float32)
rng_states = create_xoroshiro128p_states(rows * cols * d, seed=seed)
cuda_init_weights[rows * cols * d // tpb + 1, tpb](rng_states, d_weights)
\end{minted}
\captionof{listing}{Incialización aleatoria de la matriz de pesos.\\}
\label{code:numbainitweights}
\end{code}

Una vez estos pesos han sido generados se realiza un proceso iterativo con los subproblemas 2 al 5 hasta alcanzar el número de iteraciones máximo determinado por el usuario. Cada nodo ejecutor de Spark se encarga de calcular los resultados sobre un subconjunto de muestras, combinándolos al final de la iteración el nodo que lleva el control de la ejecución. Este proceso es realizado utilizando la función \textit{mapPartitions} de \textit{Spark} que nos permite realizar la misma operación sobre las diferentes particiones del \textit{RDD} que contiene los datos y obtener otro \textit{RDD} reuniendo los resultados obtenidos de la operación.

\subsubsection{Cálculo de las distancias euclídeas entre todas las muestras y los pesos.}
El cálculo de la distancia euclídea es una operación masiva uno a uno realizada con todas las muestras de entrada con cada uno de los vectores que representa los pesos de las neuronas del mapa. Para optimizar este operación en \textit{CUDA} hemos realizados dos optimizaciones. Por un lado, puesto que nuestro objetivo final es encontrar la posición de la combinación muestra-neurona con la distancia mínima podemos eliminar el cálculo de la raíz cuadrada de la fórmula de la distancia euclídea pues es una operación costosa y no altera la relación de orden generada. Por otro lado, utilizamos la memoria compartida para asegurarnos de que algunos elementos que son ampliamente utilizados en el bloque permanezca en esa caché de acceso más rápido que la memoria global. En concreto, en este caso, lanzamos una malla bidimenisonal de bloques con tantas filas como número de neuronas y columnas como el número de muestras dividido por el tamaño de un bloque más una. Dada esta distribución, en el mismo bloque estamos calculando la distancia entre la neurona con el asociado a la fila en la malla y el subcojunto de muestras asociada a la columna de la malla. Puesto que los pesos de la neurona son utilizados en todo su bloque, éstos son cargados en la memoria compartida del bloque.


\begin{code}
\begin{minted}[fontsize=\footnotesize]{python}
@cuda.jit
def euclidean_distance(samples, weights, distances, nsamples, d):
    # 1. Tomamos los índices que nos correspoden
    neuron_idx = cuda.blockIdx.x
    samples_idx = cuda.blockIdx.y * cuda.blockDim.x + cuda.threadIdx.x
    
    
    # 2. Ponemos los pesos de la neurona en memoria compartida
    shared_weights = cuda.shared.array(shape=0, dtype=numba.float32)
    for i in range(d // cuda.blockDim.x + 1):
        i_stride = i * cuda.blockDim.x
        my_pos = i_stride + cuda.threadIdx.x
        if my_pos < d:
            shared_weights[my_pos] = weights[neuron_idx * d + my_pos]
            
    cuda.syncthreads()
    
    # 3. Procedemos a realizar el cálculo de la distancia si procede
    if samples_idx < nsamples:
        distance = 0.0
        for i in range(d):
            i_distance = samples[samples_idx * d + i] - shared_weights[i]
            distance += i_distance * i_distance
            
        distances[samples_idx, neuron_idx] = distance
\end{minted}
\captionof{listing}{Cálculo de la distancia euclídea.\\}
\label{code:euclideandistance}
\end{code}

\subsubsection{Encontrar la BMU para cada muestra.}
Todas las distancias del subproblema anterior fueron guardadas en una matriz bidimensional donde la fila representa a la muestra y la columna a la neurona. Por tanto, hemos de encontrar el valor en mínimo en cada fila. \\


\begin{figure}[ht]
\centering
\includegraphics[scale=0.5]{imagenes/parallel_reduce.png}
\caption{Una reducción paralela de una sumatoria en CUDA.}
\label{image:cudareduction}
\end{figure}

Para encontrar el mínimo en un \textit{array} utilizamos un algoritmo frecuentemente utilizando en la GPU: \textbf{la reducción}. Si los elementos de la reducción, caben en un bloque, los mismos son puestos en la memoria compartida del bloque y se simula un recorrido sobre un árbol binario balanceado hacia arriba, tomando los elementos cargadas en memoria compartida como las hojas y alcanzado el resultado final en la raíz. Para que el algoritmo funcione, la operación en cuestión ha de cumplir la propiedad asociativa. Mientras que el uso más habitual de este algoritmo es para realizar la sumatoria nosotros la utilizamos para encontrar el mínimo manteniendo también control del índice que le corresponde. Si todos los datos no caben en un bloque, se lanzan tantos bloques como sean necesarios y este proceso es repetido hasta que queda un único resultado. \\

Puesto que nosotros queremos realizar el proceso para múltiples filas con las mismas dimensiones. Si necesitamos $P$ bloques para resolver la reducción de una fila lanzamos los $N \cdot P$ correspondientes a la vez para obtener la máxima ganancia. Podemos consultar con más detalle cómo realizar una implementación de una reducción de alto rendimiento en \textit{CUDA} en la referencia bibliográfica \cite{reduction}.

\subsubsection{Actualizar la matriz de pesos.}
La fórmula para actualizar cada vector de pesos del mapa depende de dos sumatorias, una en el numerador y otra en el denominador.\\
$$
 W_{i, j} = \frac{\sum_{k=0}^{f} \delta_f(c, [i,j]) \cdot  X(T_k) }{\sum_{k=0}^{f} \delta_f(c, [i,j])}
$$\\

Para utilizar los múltiples nodos ejecutores de \textit{Spark} y sacar el máximo rendimiento, cada nodo realiza la sumatoria de sus muestras guardando el numerador y denominador parciales que les corresponden a sus particiones para, a continuación, ser combinados en el nodo de \textit{Spark} que dirige la ejecución del algoritmo.\\

El cálculo parcial de los numeradores y denominadores parciales se realiza utilizando \textbf{operaciones atómicas}, en concreto, la suma atómica. Las operaciones atómicas son operaciones que sufren de una mayor latencia que su correpondiente operación normal pero evitan condiciones de carrera si múltiples hebras intentan modificar la misma posición de memoria pues realizan la lectura y la actualización del dato en una única operación. La necesidad de utilizar este tipo de operaciones radica en la posibilidad que existe de que la BMU de varias muestras sean la misma neurona y, por tanto, varias hebras intenten modificar la sumatoria de numerador o denominador de la misma neurona al mismo tiempo. Además de esta alternativa, que es por la que hemos optado para realizar el desarrollo de esta parte del algoritmo, podríamos haber generado una estructura auxiliar que para cada neurona contenga $N \cdot d$ entradas para la sumatoria del numerador y otras $N$ para la sumatoria del denominador y posteriormente realizar una reducción con la operación de suma para obtener los resultados deseados. Sin embargo, esta alternativa, como podemos observar, sufriría de una gran complejidad espacial a la hora de afrontar problemas de \textit{Big Data}, limitando la escalabilidad de la solución propuesta a la hora de afrontar problemas de mayor número de muestras o mapas de neuronas más grandes.

Para lanzar nuestro kernel aprovechando la memoria compartida usamos una malla de tantas filas como números de muestras y tantas columnas como 
números de neuronas haya en el mapa divido entre el tamaño del bloque más una. Puesto que los bloques de cada fila de la malla, comprueban si la muestra de la fila está en el rango de actualización de la neuronas que le corresponde a cada bloque mantenemos los datos de la muestra en memoria compartida para asegurarnos de un acceso rápido a los mismos.

\begin{code}
\begin{minted}[fontsize=\footnotesize]{python}
@cuda.jit
def prepare_update(bmu, samples, num, den, 
    nrows, ncols, d, sigma_squared):
    # 1. Tomamos los índices que correspondan
    sample_idx = cuda.blockIdx.x
    neuron_idx = cuda.blockIdx.y * cuda.blockDim.x + cuda.threadIdx.x
   
    # 2. Metemos en memoria compartida la muestra que se lee en todo el bloque
    shared_sample = cuda.shared.array(shape=0, dtype=numba.float32)
    for i in range(d // cuda.blockDim.x + 1):
        i_stride = i * cuda.blockDim.x
        my_pos = i_stride + cuda.threadIdx.x
        if my_pos < d:
            shared_sample[my_pos] = samples[sample_idx * d + my_pos]
    cuda.syncthreads()
    
    # 3. Si procede realizar cálculos los hacemos
    if neuron_idx < nrows * ncols:
        bmu_row = bmu[sample_idx] // ncols
        bmu_col = bmu[sample_idx] % ncols
        neuron_row = neuron_idx // ncols
        neuron_col = neuron_idx % ncols
        
        dist = (neuron_row - bmu_row) * (neuron_row - bmu_row) + \
               (neuron_col - bmu_col) * (neuron_col - bmu_col)
        
        if dist <= sigma_squared:
            hck = math.exp(-dist/(2 * sigma_squared))
            # Guardamos sumatoria del denominador
            cuda.atomic.add(den, neuron_row * ncols + neuron_col, hck)
            # Guardamos sumatoria del numerador
            for i in range(d):
                cuda.atomic.add(num, neuron_row*ncols*d + neuron_col*d+i
                                hck * shared_sample[i])
\end{minted}
\captionof{listing}{Cálculo de numeradores y denominadores parciales.\\}
\label{code:partials}
\end{code}

Una vez todos los resultados han sido recopilados, lanzamos un último kernel que juntará los resultados parciales obtenidos y realizará la división, actualizando los pesos si la neurona en cuestión ha sido BMU de alguna muestra o dejando los pesos de la iteración anterior en caso contrario. En este caso lanzamos una malla unidimensional de tantos bloques como número de neuronas haya entre el tamaño de un bloque más uno. Cada hebra se encarga de realizar las sumas parciales de su neurona asociada y realizar la actualización de su vector de pesos en la matriz si procede.

\begin{code}
\begin{minted}[fontsize=\footnotesize]{python}
@cuda.jit
def finish_update(weights, partials, numParts, nrows, ncols, d):
     idx = cuda.grid(1)
    if idx < nrows * ncols:
        row = idx // ncols
        col = idx % ncols
        
        
        # a) Sumamos todos los parciales en el primer array
        numsize = nrows * ncols * d
        densize = nrows * ncols
        fullsize = numsize + densize
        for i in range(numParts - 1):
            # Suma de numeradores
            for k in range(d):
                pos = fullsize * i + row * ncols * d + col * d + k
                partials[row * ncols * d + col * d + k] += partials[pos]
            # Suma de denominadores
            pos = fullsize * i + numsize + row * ncols + col
            partials[numsize + row * ncols + col] += partials[pos]
            
    cuda.syncthreads()
    
    if idx < nrows * ncols:
        # b) Si no es 0 el denominador realizamos el cambio
        if partials[numsize + row * ncols + col] != 0:
            for k in range(d):
                mypos = row * ncols * d + col * d + k
                denpos = numsize + row * ncols + col
                weights[mypos] =  partials[mypos] / partials[denpos]
\end{minted}
\captionof{listing}{Actualización final de la matriz de pesos.\\}
\label{code:ending}
\end{code}

\subsubsection{Actualizar los parámetros de control.}
Los parámetros de control $\eta$ y $\sigma$ son sólo dos parámetros a modificar por iteración y cuyo cálculo se corresponde a una única operación, por lo que nos es susceptible a ser paralelizado en la GPU y será realizado en el nodo de Spark que dirige la ejecución del clúster si todavía no se ha alcanzado el máximo de iteraciones.
Si se ha alcanzado el máximo de iteraciones el algoritmo termina y la matriz de vectores de pesos de las neuronas de esa última iteración es la solución obtenida.

\begin{figure}[ht]
\centering
\includegraphics[scale=0.35]{imagenes/flujosombatch.png}
\caption{Diagrama de flujo para el mapa autoorganizado batch.}
\label{img:sombatch}
\end{figure}

\newpage
\section{Desarrollo de un modelo de árbol de decisión.}
La implementación del modelo de árbol de decisión se basa en CUDT \cite{cudt}, que a su vez se fundamenta en SPRINT \cite{sprint} y la operación de \textit{scan}.

\subsection{Lista de atributos.}
Una lista de atributos, es una estructura auxiliar, procedente de SPRINT \cite{sprint}, utilizada para representar las clases y los atributos asociados a una muestra. Una lista de atributos tiene una estructura similar a la siguiente tabla:

\begin{table}[ht]
\centering
\begin{tabular}{@{}lll@{}}
\toprule
Valor & Clase & ID Muestra \\ \midrule
2,5   & 0     & 0          \\
4,7   & 0     & 1          \\
0,1   & 1     & 2          \\
1,0   & 1     & 3          \\ \bottomrule
\end{tabular}
\caption{Una lista de atributos sin ordenar.}
\label{tab:ejlistaatributos}
\end{table}

Las columnas de la tabla \ref{tab:ejlistaatributos} son:
\begin{itemize}
	\item \textbf{Valor}, que se corresponde al valor que toma el atributo al que correponde la tabla en la muestra representada en la fila.
	\item \textbf{Clase}, que se correponde a la etiqueta de salida asoaciada a la muestra de la fila.
	\item \textbf{ID Muestra}, que se correponde al identificador de la muestra. Al principio, se correponde al número de fila empezando por 0.
\end{itemize}

Una vez esta estructura es generada para cada atributo del problema en cuestión, es ordenada por orden creciente según la columna ``Valor''.

\subsection{Esquema general del algoritmo implementado.}
\begin{figure}[ht]
\centering
\includegraphics[scale=0.35]{imagenes/esquemadtree.png}
\caption{Diagrama de flujo de la implementación del árbol de decisión.}
\label{img:dtree}
\end{figure}
Al inicio del algoritmo, tras generar las listas de atributos, se genera un nodo raíz que comprende todas las muestras del conjunto. En ese nodo, hemos de encontrar para qué atributo y qué valor realizamos la partición óptima de los datos. Para ello, se consideran todas las listas de atributos y se toma como posible punto de corte el punto medio entre un valor y el siguiente si no se trata del mismo valor. Asociada a cada una de las particiones, se calcula el criterio de Gini. Una vez realizados todos los cálculos, tomamos como punto de corte aquella que menor criterio de Gini nos de. Utilizando ese punto de corte, generamos dos nuevos nodos para la siguiente iteración, uno que contiene todos los puntos menores o iguales que dicho punto de corte y otro con los mayores. Además, dicho punto es el que utilizamos para generar nuestro nodo de decisión en el árbol entrenado.  Este proceso se repite hasta que no quedan nodos por evaluar. Un nodo no ha de ser evaluado si:\\

\begin{itemize}
	\item a) Todos los elementos del nodo pertenecen a la misma clase. En ese caso, en vez de un nodo de decisión, generamos un nodo terminal con la clase correspondiente.
	\item b) Se ha especificado un criterio de profundidad máxima y dicha profundidad ha sido alcanzada. En ese caso, generamos un nodo terminal con la clase más representativa del nodo.
	\item c) Se ha especificado un límite para el número de elementos mínimo que puede contener y ha sido alcanzado. En ese caso, generamos un nodo terminal de manera similar al caso anterior.
\end{itemize}



\subsection{La operación de scan.}
Una de las claves del uso de la lista de atributos, es que, para los problemas de \textbf{clasificación binaria}, que son los únicos que nuestro modelo es capaz de resolver, si codificamos una clase como $0$ (a partir de ahora llamada \textit{clase negativa}) y otra como $1$ (\textit{clase positiva}) si realizamos una suma acumulada sobre el subconjunto de filas de un nodo de la columna ``Clase'' podríamos tener control de cuántos elementos hay en cada clase tanto para todas las particiones. Para realizar la suma acumulada existe un algoritmo ampliamente utilizada en el mundo de la GPU denominado \textit{scan}.

El \textit{scan} \cite{scan}, suma acumulada o suma prefija, es una operación que utiliza un operador binario, $\oplus$, que cumpla la propiedad asociativa y utilizada sobre un \textit{array} de $n$ elementos. Existen dos formas de realizar el \textit{scan}: inclusivo y exclusivo. El scan inclusivo empieza con el primer elemento del array y va a realizando una suma acumulada. El \textit{scan} exclusivo empieza con el elemento neutro de la operación y realiza una suma acumulada de todos los elementos hasta el penúltimo. En la implementación realizada hemos utilizado una operación de \textit{scan} exclusivo que además devuelve el total de la suma del array cubriendo ambos casos. Para los propósitos de este documento, cada vez que hablemos de \textit{scan} nos estaremos refiriendo al \textit{scan exclusivo}. Por tanto la operación de \textit{scan} sobre un array nos devuelve lo siguiente:

$$scan([a_0, a_1, a_2, ..., a_{n-1}]) = [I, a_0, (a_0 \oplus a_1), (a_0 \oplus a_1 \oplus a_2), ..., (a_0 \oplus a_1 \oplus a_2 \oplus ... \oplus a_{n-1})]$$

La implementación en \textit{CUDA} de la operación se realiza, utilizando una técnica frecuente para estos dispositivos, simular el uso de un árbol binario balanceado utilizando la memoria compartida del bloque. Imaginamos que todos los elementos de un bloque son los nodos terminales de un árbol y los metemos en la memoria compartida del bloque y realizamos dos fases sobre ello. En la primera fase, \textit{up-sweep} (figura \ref{image:upsweep}), se realiza el recorrido de los nodos terminales a la raíz realizando las sumas en sus nodos padre y manteniendo las sumas paciales. En la segunda fase \textit{down-sweep} (figura \ref{image:downsweep}), se utilizan los resultados parciales obtenidos para completar los resultados en la suma acumulada. Para arrays cuya dimensión no cabe en un bloque dicho array es subdividido en múltiples subconjuntos contiguos del mismo tamaño que sí caben en un bloque (si sobran elementos en el último bloque son inicalizados con el elemento neutro de la operación) y se genera el scan sobre todos los subconjuntos así como se almacena la sumatoria (puesto en que nuestra caso la operación es la suma) de todos los elementos del bloque. Una vez finalizado, dichas sumatorias se aplican a los bloques que le preceden en posición, obtiendo el resultado final deseado.


\begin{figure}[ht]
\centering
\includegraphics[scale=0.6]{imagenes/upsweep.png}
\caption{Fase up-sweep del scan.}
\label{image:upsweep}
\end{figure}

\begin{figure}[ht]
\centering
\includegraphics[scale=0.6]{imagenes/downsweep.png}
\caption{Fase down-sweep del scan.}
\label{image:downsweep}
\end{figure}


\subsection{Cálculo del criterio de Gini.}
Dado que sólo vamos a calcular el criterio de Gini para problemas de clasificación binaria hemos simplificado el mismo para ahorrarnos algunas operaciones a la hora de realizar el cálculo:

$$CRITERIO(A,v) = \frac{|i: A_i \leq v|}{N} \cdot GINI(|i: A_i \leq v|) + \frac{|i: A_i > v|}{N} \cdot GINI(|i: A_i > v|)$$

$$GINI(D) = 1 - \frac{T_D^2}{N_D^2} - \frac{F_D^2}{N_D^2}$$

Siendo $N_D$ el total de las muestras en el nodo $D$, $T_D$ el total de muestras pertenecientes a la clase positiva y $F_D$ el total de muestras pertenencientes a la clase negativa. Tenemos que:

$$F_D = N_D - T_D$$
Sustituyendo obtenemos que:

$$GINI(D) = \frac{N_D^2-T_D^2- (N_D - T_D)^2}{N_D^2} = \frac{N_D^2 - T_D^2 - (N_D^2+T_D^2 - 2 N_D T_D)}{N_D^2}$$
$$GINI(D) = \frac{-2T_D^2 + 2N_DT_D}{N_D^2} = 2 \frac{T_D(N_D-T_d)}{N_D^2}$$

$$CRITERIO = \frac{N_\leq}{N}\frac{2T_\leq(N_\leq - T_\leq)}{N_\leq^2} + \frac{N_>}{N}\frac{2T_>(N_> - T_>)}{N_>^2}$$
$$CRITERIO = \frac{2}{N}\Big(\frac{T_\leq(N_\leq - T_\leq)}{N_{\leq}} + \frac{T_>(N_> - T_>)}{N_>}\Big)$$

Puesto que además, no es de nuestro interés el valor específico sino obtener el valor óptimo, podemos ahorrarnos la multiplicación por $\frac{2}{N}$. Así pues, calculamos el criterio de la siguiente manera:

$$CRITERIO' = \Big(\frac{T_\leq(N_\leq - T_\leq)}{N_{\leq}} + \frac{T_>(N_> - T_>)}{N_>}\Big)$$

El valor de $CRITERIO'$ oscilará entre 0 y $\frac{N}{2}$ y buscaremos siempre obtener el mínimo valor para este criterio. Dicha búsqueda se realizará de manera similar a la realizada para el modelo anterior con una reducción para encontrar el índice mínimo en cada nodo.

\subsection{Reorganización de la listas de atributos.}
Para finalizar la evaluación de los nodos de un nivel podemos volver a aprovechar la operación de \textit{scan} para reorganizar el orden de los elementos de la lista de atributos sin necesidad de ejecutar ningún algoritmo de ordenación. Una vez se ha seleccionado la combinación de mejor lista de atributos para un nodo y su punto de corte, puesto que esta lista ya estaba ordenada, todos los elementos hasta el punto de corte pertenecen al nodo hijo izquierdo y los posteriores al nodo hijo derecho. Además, puesto que tenemos en la lista de atributos el cammpo ``ID Muestra'', podemos generar fácilmente un array de booleanos donde cada elemento indica si la muestra con el ID asociado a su posición pertenece al hijo izquierdo o al hijo derecho. Una vez hecho esto, podemos recorrer cada nodo activo de la lista de atributos y utilizar este array auxiliar y la operación de scan para determinar la nueva posición que va a ocupar el elemento dentro del nodo. Esto se realiza, aplicando un scan sobre las posiciones de este array que le corresponden a cada muestra del nodo que va a ir a la subdivisión izquierda. De esta manera, si la muestra pertenece a la subdivisión izquierda su nueva posición será la suma acumulada de elementos de la subdivisión izquierda menos uno (porque empezamos a indexar el array en 0) y en caso de pertenecer a la subdivisión de la derecha será la posición más la diferencia del total de elementos de la subdivisión izquierda (suma acumulada total) con la suma acumulada de elementos de la subdivisión izquierda menos uno.

\subsection{Limitaciones y uso de Spark.}
Como comprobaremos posteriormente, este modelo, al requerir de la evaluación independiente de múltiples nodos y no presentar técnicas de poda avanzadas no escala bien con la generación de árboles profundos o completos. Es por eso que, para afrontar problemas de mayores dimensiones, en vez de generar un único árbol, vamos a generar tantas particiones del \textit{RDD} de \textit{Spark} como árboles deseemos y montar un modelo de \textit{random forest}, en el que en cada partición tenemos un conjunto aleatorio de muestras tomadas sin reemplazo y consideramos todos los atributos para todos los árboles. La clasificación proporcionada por el modelo viene dada por el clase mayoritariamente votada por el conjunto de árboles.

